{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2533ef",
   "metadata": {},
   "source": [
    "# Computing cross-entropy for several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8898c25a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from main import *\n",
    "\n",
    "params = {\n",
    "      'text.usetex': True,\n",
    "      'font.family': 'sans serif'\n",
    "}\n",
    "matplotlib.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43926f48-02f7-4ecd-aa9f-83c6d9d974d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load energy models (on ImageNet color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef250b-ed6f-4b2a-89a3-64e56fcc3947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalclean_imagenet64_color_lr0.0005_1Msteps10decays: retrieved model at step 1000000 and test loss 4.22e-01\n"
     ]
    }
   ],
   "source": [
    "def load_exp(name, step=\"last\", log=True, dataloaders=False):\n",
    "    \"\"\" Load an experiment with a given name. step can be an integer, \"best\", or \"last\" (default). \"\"\"\n",
    "    exp_dir = Path(\"models\") / name\n",
    "\n",
    "    with open(exp_dir / \"args.json\") as f:\n",
    "        args_dict = json.load(f)\n",
    "\n",
    "    ctx = TrainingContext(**args_dict, step=step, key_remap=None, seed=None, dataloaders=dataloaders, writer=False)\n",
    "    if log:\n",
    "        print(f\"{name}: retrieved model at step {ctx.step} and test loss {ctx.test_perf.loss:.2e}\")\n",
    "\n",
    "    # Disable DataParallel (needed for Hessian computation)\n",
    "    ctx.model.network = ctx.model.network.module\n",
    "\n",
    "    # Put in eval mode and disable gradients with respect to all parameters.\n",
    "    ctx.model.eval()\n",
    "    for p in ctx.model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    return ctx\n",
    "\n",
    "ctxs = {\n",
    "    \"color\": load_exp(\"finalclean_imagenet64_color_lr0.0005_1Msteps10decays\", dataloaders=True),\n",
    "    # Add other models here as needed.\n",
    "}\n",
    "default_ctx = ctxs[\"color\"]\n",
    "dataset_info = default_ctx.dataset_info\n",
    "d = dataset_info.dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f769f3",
   "metadata": {},
   "source": [
    "## Compute cross-entropy/NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b82b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cdae66d9714f468fbad7504af341c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- forward: 18s660ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf66480cb2004c01a335389fe60b3fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- forward: 18s682ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cb5410990e4f2f8a4cb9deb68ece09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- forward: 18s498ms\n",
      "clean_lr0.0005: train NLL 3.33, test NLL 3.36\n"
     ]
    }
   ],
   "source": [
    "# Compare their probabilities on clean images\n",
    "\n",
    "def samples_energy(dataloader, t=0):\n",
    "    default_ctx.time_tracker.reset()\n",
    "\n",
    "    xs = []\n",
    "    es = defaultdict(list)\n",
    "    for x in tqdm(dataloader):\n",
    "        x = x[0]\n",
    "        xs.append(x.cpu())\n",
    "        clean = x.cuda()\n",
    "        input = model_input(clean, noise_level=t)\n",
    "\n",
    "        default_ctx.time_tracker.switch(\"forward\")\n",
    "        for k, c in ctxs.items():\n",
    "            output = c.model(input, compute_scores=False, create_graph=False)  # (B,)\n",
    "            es[k].append(output.energy.cpu())\n",
    "\n",
    "    print(default_ctx.time_tracker.pretty_print())\n",
    "\n",
    "    xs = torch.cat(xs, dim=0)\n",
    "    es = {k: torch.cat(e, dim=0) for k, e in es.items()}\n",
    "    return xs, es\n",
    "\n",
    "# Compute energies in nats (summed over dimensions) over the whole dataset.\n",
    "train_dataloader = default_ctx.new_dataloader(train=True, batch_size=2048, num_samples=50_000)  # We don't need the full dataset here.\n",
    "imgs_train, energies_train = samples_energy(train_dataloader)\n",
    "test_dataloader = default_ctx.new_dataloader(train=False, batch_size=2048)\n",
    "imgs_test, energies_test = samples_energy(test_dataloader)\n",
    "\n",
    "# Compute normalization constant by computing average energy at large noise level\n",
    "t = 1e3\n",
    "test_dataloader = default_ctx.new_dataloader(train=False, batch_size=2048)\n",
    "_, energies_t = samples_energy(test_dataloader, t=t)\n",
    "constants = {key: d/2 * np.log(2 * np.pi * np.e * t) - energy.mean() for key, energy in energies_t.items()}\n",
    "\n",
    "for key in ctxs:\n",
    "    nll_train = 8 + (energies_train[key].mean() + constants[key]) / (d * np.log(2))\n",
    "    nll_test = 8 + (energies_test[key].mean() + constants[key]) / (d * np.log(2))\n",
    "    print(f\"{key}: train NLL {nll_train:.2f}, test NLL {nll_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6171cf4",
   "metadata": {},
   "source": [
    "## Releasing GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9923881",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79943efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
